import tensorflow as tf
import numpy as np
import random

test_flag = "TF"

if (test_flag == "P"):
import numpy as np
import random
        #  x(x1, x2, c), label(sum, carry) data
    x_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]])
    label = np.array([[0, 0], [1, 0], [1, 0], [0, 1], [1, 0], [0, 1], [0, 1], [1, 1]])
    # test data
    v = 0
    noise = random.gauss(0.0, v)
    x_test = x_data + noise

    # sigmoid함수 정의
    def sigmoid(x):
        return 1 / (1 + np.exp(-x))


    # gradient descnet algorithm을 위한 미분 함수
    def gra(f, x):
        delta_x = 0.01
        grad = np.zeros_like(x)
        it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
        while not it.finished:
            idx = it.multi_index
            tmp_val = x[idx]
            x[idx] = float(tmp_val) + delta_x
            fx1 = f(x)

            x[idx] = tmp_val - delta_x
            fx2 = f(x)
            grad[idx] = (fx1 - fx2) / (2 * delta_x)

            x[idx] = tmp_val
            it.iternext()
        return grad

    #layer에 들어갈 weight, bias 정의
    W1 = np.random.rand(3, 10)
    b1 = np.random.rand(10)
    W2 = np.random.rand(10, 2)
    b2 = np.random.rand(2)

    # cost fucntion 정의, 함수 내에 중간 layer 구현
    def cost(x, t):
        l1 = np.dot(x, W1) + b1
        s1 = sigmoid(l1)
        l2 = np.dot(s1, W2) + b2
        Y_ = sigmoid(l2)

        return -np.sum(t * np.log(Y_) + (1 - t) * np.log(1 - Y_))

    # 입력이 0.5보다 크면 1, 아니면 0을 출력하는 tf함수
    def tf(a):
        cond = (a > 0.5)
        return np.where(cond, 1, 0)

    #sigmoid 값을 통과한 최종값이 0.5보다 크면 1, 작으면 0이 나오도록 하는 예상 함수
    def predicted(x):
        l1 = np.dot(x, W1) + b1
        s1 = sigmoid(l1)
        l2 = np.dot(s1, W2) + b2
        Y_ = sigmoid(l2)

        return np.array(tf(Y_))
    #training 반복을 위한 train함수
    def train(_):
        return cost(x_data, label)

    #training 반복, step 100번마다 cost 출력
    learning_rate = 0.1
    for step in range(2001):
        W1 -= learning_rate * gra(train, W1)
        b1 -= learning_rate * gra(train, b1)
        W2 -= learning_rate * gra(train, W2)
        b2 -= learning_rate * gra(train, b2)
        if (step % 100 == 0):
            print("step =", step, "\ncost = ", cost(x_test, label))
    #예측값과 label 표시
    print("predicted:\n", predicted(x_test), "\nlabel:\n", label)

elif (test_flag == "TF"):

    # x(x1, x2, c), label(sum, carry) data
    x_data = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]]
                      )
    label = np.array([[0, 0], [1, 0], [1, 0], [0, 1], [1, 0], [0, 1], [0, 1], [1, 1]])
    # test data
    v = 0.35
    
    noise = random.gauss(0.0, v)
    x_test = x_data + noise

    X = tf.placeholder(tf.float32)
    Y = tf.placeholder(tf.float32)
    # layer 1 , layer1의 output의 수를 늘릴수록 cost가 낮아진다(wide neural network), layer의 수를 늘릴수록 cost가 낮아진다(deep neural network)
    W1 = tf.Variable(tf.random_normal([3, 10]), name='weight1')
    b1 = tf.Variable(tf.random_normal([10]), name='bias1')
    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)
    # 예상값 Y_, sigmoid함수를 통해 0~1값으로 바꾼다
    W2 = tf.Variable(tf.random_normal([10, 2]), name='weight2')
    b2 = tf.Variable(tf.random_normal([2]), name='bias2')
    Y_ = tf.sigmoid(tf.matmul(layer1, W2) + b2)

    # cost function과 minimize를 위한 training function
    cost = -tf.reduce_mean(Y * tf.log(Y_) + (1 - Y) * tf.log(1 - Y_))
    train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)

    # sigmoid를 통과한 값이 0.5보다 크면 1로 한다
    predicted = tf.cast(Y_ > 0.5, dtype=tf.float32)
    # 결과값의 정확도 계산
    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))


    # running session
    with tf.Session() as sess:
        # 변수값을 초기화한다
        sess.run(tf.global_variables_initializer())
        
        #training 반복, step 100번마다 cost 출력
        for step in range(10001):
            sess.run(train, feed_dict={X: x_data, Y: label})
            if step % 100 == 0:
                print("step =", step, "\ncost =", sess.run(cost,feed_dict={X : x_data, Y : label}))


        # 예상 결과와 정확도
        p, a = sess.run([predicted, accuracy], feed_dict={X: x_test, Y: label})
        print("\nPredicted: ", p, "\nAccuracy: ", a)




